0: conv_in.bias: sum: 12.3477  dtype: Float32 shape: [320]
1: conv_in.weight: sum: 28.3308  dtype: Float32 shape: [320,4,3,3]
2: conv_norm_out.bias: sum: 11.7295  dtype: Float32 shape: [320]
3: conv_norm_out.weight: sum: 11.8293  dtype: Float32 shape: [320]
4: conv_out.bias: sum: 0.1199  dtype: Float32 shape: [4]
5: conv_out.weight: sum: 126.1931  dtype: Float32 shape: [4,320,3,3]
6: down_blocks.0.attentions.0.norm.bias: sum: 11.6294  dtype: Float32 shape: [320]
7: down_blocks.0.attentions.0.norm.weight: sum: 12.001  dtype: Float32 shape: [320]
8: down_blocks.0.attentions.0.proj_in.bias: sum: 9.3963  dtype: Float32 shape: [320]
9: down_blocks.0.attentions.0.proj_in.weight: sum: 291.3827  dtype: Float32 shape: [320,320]
10: down_blocks.0.attentions.0.proj_out.bias: sum: 2.4497  dtype: Float32 shape: [320]
11: down_blocks.0.attentions.0.proj_out.weight: sum: -488.9658  dtype: Float32 shape: [320,320]
12: down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 73.4561  dtype: Float32 shape: [320,320]
13: down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 1.6699  dtype: Float32 shape: [320]
14: down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 200.688  dtype: Float32 shape: [320,320]
15: down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 274.6749  dtype: Float32 shape: [320,320]
16: down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 256.8734  dtype: Float32 shape: [320,320]
17: down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 526.076  dtype: Float32 shape: [320,1024]
18: down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: -46.8245  dtype: Float32 shape: [320]
19: down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 230.8695  dtype: Float32 shape: [320,320]
20: down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 254.5729  dtype: Float32 shape: [320,320]
21: down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 271.1167  dtype: Float32 shape: [320,1024]
22: down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 43.3711  dtype: Float32 shape: [2560]
23: down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 386.4599  dtype: Float32 shape: [2560,320]
24: down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: 24.7765  dtype: Float32 shape: [320]
25: down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 735.3786  dtype: Float32 shape: [320,1280]
26: down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias: sum: 10.2426  dtype: Float32 shape: [320]
27: down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight: sum: 11.9995  dtype: Float32 shape: [320]
28: down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias: sum: 11.3278  dtype: Float32 shape: [320]
29: down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight: sum: 11.869  dtype: Float32 shape: [320]
30: down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias: sum: 13.0615  dtype: Float32 shape: [320]
31: down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight: sum: 11.9025  dtype: Float32 shape: [320]
32: down_blocks.0.attentions.1.norm.bias: sum: 12.0179  dtype: Float32 shape: [320]
33: down_blocks.0.attentions.1.norm.weight: sum: 11.915  dtype: Float32 shape: [320]
34: down_blocks.0.attentions.1.proj_in.bias: sum: 44.3924  dtype: Float32 shape: [320]
35: down_blocks.0.attentions.1.proj_in.weight: sum: 335.7233  dtype: Float32 shape: [320,320]
36: down_blocks.0.attentions.1.proj_out.bias: sum: 11.514  dtype: Float32 shape: [320]
37: down_blocks.0.attentions.1.proj_out.weight: sum: -36.1348  dtype: Float32 shape: [320,320]
38: down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: 119.3169  dtype: Float32 shape: [320,320]
39: down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 4.3263  dtype: Float32 shape: [320]
40: down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 875.1085  dtype: Float32 shape: [320,320]
41: down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: 292.093  dtype: Float32 shape: [320,320]
42: down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 249.1614  dtype: Float32 shape: [320,320]
43: down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 318.1219  dtype: Float32 shape: [320,1024]
44: down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: 6.8126  dtype: Float32 shape: [320]
45: down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: -182.6719  dtype: Float32 shape: [320,320]
46: down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: 261.6514  dtype: Float32 shape: [320,320]
47: down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: 314.9889  dtype: Float32 shape: [320,1024]
48: down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 44.1833  dtype: Float32 shape: [2560]
49: down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 788.1666  dtype: Float32 shape: [2560,320]
50: down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: 14.7859  dtype: Float32 shape: [320]
51: down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: 1543.9186  dtype: Float32 shape: [320,1280]
52: down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias: sum: 11.8574  dtype: Float32 shape: [320]
53: down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight: sum: 11.9012  dtype: Float32 shape: [320]
54: down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias: sum: 12.2481  dtype: Float32 shape: [320]
55: down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight: sum: 11.8718  dtype: Float32 shape: [320]
56: down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias: sum: 11.6233  dtype: Float32 shape: [320]
57: down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight: sum: 11.8969  dtype: Float32 shape: [320]
58: down_blocks.0.downsamplers.0.conv.bias: sum: 10.8226  dtype: Float32 shape: [320]
59: down_blocks.0.downsamplers.0.conv.weight: sum: 580.5663  dtype: Float32 shape: [320,320,3,3]
60: down_blocks.0.resnets.0.conv1.bias: sum: 12.2731  dtype: Float32 shape: [320]
61: down_blocks.0.resnets.0.conv1.weight: sum: 548.6778  dtype: Float32 shape: [320,320,3,3]
62: down_blocks.0.resnets.0.conv2.bias: sum: 8.7568  dtype: Float32 shape: [320]
63: down_blocks.0.resnets.0.conv2.weight: sum: 631.6872  dtype: Float32 shape: [320,320,3,3]
64: down_blocks.0.resnets.0.norm1.bias: sum: 11.6448  dtype: Float32 shape: [320]
65: down_blocks.0.resnets.0.norm1.weight: sum: 11.886  dtype: Float32 shape: [320]
66: down_blocks.0.resnets.0.norm2.bias: sum: 12.4929  dtype: Float32 shape: [320]
67: down_blocks.0.resnets.0.norm2.weight: sum: 11.9579  dtype: Float32 shape: [320]
68: down_blocks.0.resnets.0.time_emb_proj.bias: sum: 12.1301  dtype: Float32 shape: [320]
69: down_blocks.0.resnets.0.time_emb_proj.weight: sum: 370.48  dtype: Float32 shape: [320,1280]
70: down_blocks.0.resnets.1.conv1.bias: sum: 11.5632  dtype: Float32 shape: [320]
71: down_blocks.0.resnets.1.conv1.weight: sum: 754.1522  dtype: Float32 shape: [320,320,3,3]
72: down_blocks.0.resnets.1.conv2.bias: sum: 11.3215  dtype: Float32 shape: [320]
73: down_blocks.0.resnets.1.conv2.weight: sum: 632.13  dtype: Float32 shape: [320,320,3,3]
74: down_blocks.0.resnets.1.norm1.bias: sum: 11.9867  dtype: Float32 shape: [320]
75: down_blocks.0.resnets.1.norm1.weight: sum: 11.9694  dtype: Float32 shape: [320]
76: down_blocks.0.resnets.1.norm2.bias: sum: 11.8861  dtype: Float32 shape: [320]
77: down_blocks.0.resnets.1.norm2.weight: sum: 11.8793  dtype: Float32 shape: [320]
78: down_blocks.0.resnets.1.time_emb_proj.bias: sum: 11.4514  dtype: Float32 shape: [320]
79: down_blocks.0.resnets.1.time_emb_proj.weight: sum: 385.9225  dtype: Float32 shape: [320,1280]
80: down_blocks.1.attentions.0.norm.bias: sum: 19.7203  dtype: Float32 shape: [640]
81: down_blocks.1.attentions.0.norm.weight: sum: 16.841  dtype: Float32 shape: [640]
82: down_blocks.1.attentions.0.proj_in.bias: sum: 19.669  dtype: Float32 shape: [640]
83: down_blocks.1.attentions.0.proj_in.weight: sum: 308.6554  dtype: Float32 shape: [640,640]
84: down_blocks.1.attentions.0.proj_out.bias: sum: 20.3392  dtype: Float32 shape: [640]
85: down_blocks.1.attentions.0.proj_out.weight: sum: 1074.804  dtype: Float32 shape: [640,640]
86: down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: -1615.8099  dtype: Float32 shape: [640,640]
87: down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 28.4512  dtype: Float32 shape: [640]
88: down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 322.2802  dtype: Float32 shape: [640,640]
89: down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 481.5117  dtype: Float32 shape: [640,640]
90: down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 648.7356  dtype: Float32 shape: [640,640]
91: down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 992.2071  dtype: Float32 shape: [640,1024]
92: down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: 28.1648  dtype: Float32 shape: [640]
93: down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 549.9522  dtype: Float32 shape: [640,640]
94: down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 911.9708  dtype: Float32 shape: [640,640]
95: down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 66.2397  dtype: Float32 shape: [640,1024]
96: down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 59.491  dtype: Float32 shape: [5120]
97: down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 21527.63  dtype: Float32 shape: [5120,640]
98: down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: 16.4262  dtype: Float32 shape: [640]
99: down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 761.9784  dtype: Float32 shape: [640,2560]
100: down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias: sum: 16.1777  dtype: Float32 shape: [640]
101: down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight: sum: 16.8614  dtype: Float32 shape: [640]
102: down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias: sum: 17.0859  dtype: Float32 shape: [640]
103: down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight: sum: 16.8694  dtype: Float32 shape: [640]
104: down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias: sum: 16.4587  dtype: Float32 shape: [640]
105: down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight: sum: 16.8326  dtype: Float32 shape: [640]
106: down_blocks.1.attentions.1.norm.bias: sum: 16.3444  dtype: Float32 shape: [640]
107: down_blocks.1.attentions.1.norm.weight: sum: 16.8047  dtype: Float32 shape: [640]
108: down_blocks.1.attentions.1.proj_in.bias: sum: 25.1568  dtype: Float32 shape: [640]
109: down_blocks.1.attentions.1.proj_in.weight: sum: -60.4093  dtype: Float32 shape: [640,640]
110: down_blocks.1.attentions.1.proj_out.bias: sum: 18.0409  dtype: Float32 shape: [640]
111: down_blocks.1.attentions.1.proj_out.weight: sum: 180.3503  dtype: Float32 shape: [640,640]
112: down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: 880.6139  dtype: Float32 shape: [640,640]
113: down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 5.5173  dtype: Float32 shape: [640]
114: down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 553.5732  dtype: Float32 shape: [640,640]
115: down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: 904.8795  dtype: Float32 shape: [640,640]
116: down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 234.8811  dtype: Float32 shape: [640,640]
117: down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 804.586  dtype: Float32 shape: [640,1024]
118: down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: -0.0618  dtype: Float32 shape: [640]
119: down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: 466.3344  dtype: Float32 shape: [640,640]
120: down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: 244.8056  dtype: Float32 shape: [640,640]
121: down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: 357.476  dtype: Float32 shape: [640,1024]
122: down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 60.9686  dtype: Float32 shape: [5120]
123: down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 1612.9419  dtype: Float32 shape: [5120,640]
124: down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: -22.2592  dtype: Float32 shape: [640]
125: down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: 958.2899  dtype: Float32 shape: [640,2560]
126: down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias: sum: 18.4931  dtype: Float32 shape: [640]
127: down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight: sum: 16.8386  dtype: Float32 shape: [640]
128: down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias: sum: 19.8544  dtype: Float32 shape: [640]
129: down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight: sum: 16.8576  dtype: Float32 shape: [640]
130: down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias: sum: 17.1631  dtype: Float32 shape: [640]
131: down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight: sum: 16.8363  dtype: Float32 shape: [640]
132: down_blocks.1.downsamplers.0.conv.bias: sum: 17.3673  dtype: Float32 shape: [640]
133: down_blocks.1.downsamplers.0.conv.weight: sum: 1441.3339  dtype: Float32 shape: [640,640,3,3]
134: down_blocks.1.resnets.0.conv1.bias: sum: 15.5108  dtype: Float32 shape: [640]
135: down_blocks.1.resnets.0.conv1.weight: sum: 998.8036  dtype: Float32 shape: [640,320,3,3]
136: down_blocks.1.resnets.0.conv2.bias: sum: 19.5836  dtype: Float32 shape: [640]
137: down_blocks.1.resnets.0.conv2.weight: sum: 1367.9417  dtype: Float32 shape: [640,640,3,3]
138: down_blocks.1.resnets.0.conv_shortcut.bias: sum: 19.6653  dtype: Float32 shape: [640]
139: down_blocks.1.resnets.0.conv_shortcut.weight: sum: 287.0217  dtype: Float32 shape: [640,320,1,1]
140: down_blocks.1.resnets.0.norm1.bias: sum: 10.7764  dtype: Float32 shape: [320]
141: down_blocks.1.resnets.0.norm1.weight: sum: 11.9081  dtype: Float32 shape: [320]
142: down_blocks.1.resnets.0.norm2.bias: sum: 16.7247  dtype: Float32 shape: [640]
143: down_blocks.1.resnets.0.norm2.weight: sum: 16.9016  dtype: Float32 shape: [640]
144: down_blocks.1.resnets.0.time_emb_proj.bias: sum: 15.3819  dtype: Float32 shape: [640]
145: down_blocks.1.resnets.0.time_emb_proj.weight: sum: 690.0588  dtype: Float32 shape: [640,1280]
146: down_blocks.1.resnets.1.conv1.bias: sum: 16.7806  dtype: Float32 shape: [640]
147: down_blocks.1.resnets.1.conv1.weight: sum: 2108.2856  dtype: Float32 shape: [640,640,3,3]
148: down_blocks.1.resnets.1.conv2.bias: sum: 17.5794  dtype: Float32 shape: [640]
149: down_blocks.1.resnets.1.conv2.weight: sum: 1248.6058  dtype: Float32 shape: [640,640,3,3]
150: down_blocks.1.resnets.1.norm1.bias: sum: 17.43  dtype: Float32 shape: [640]
151: down_blocks.1.resnets.1.norm1.weight: sum: 16.9015  dtype: Float32 shape: [640]
152: down_blocks.1.resnets.1.norm2.bias: sum: 16.8703  dtype: Float32 shape: [640]
153: down_blocks.1.resnets.1.norm2.weight: sum: 16.8709  dtype: Float32 shape: [640]
154: down_blocks.1.resnets.1.time_emb_proj.bias: sum: 16.6934  dtype: Float32 shape: [640]
155: down_blocks.1.resnets.1.time_emb_proj.weight: sum: 649.1908  dtype: Float32 shape: [640,1280]
156: down_blocks.2.attentions.0.norm.bias: sum: 23.4652  dtype: Float32 shape: [1280]
157: down_blocks.2.attentions.0.norm.weight: sum: 23.8478  dtype: Float32 shape: [1280]
158: down_blocks.2.attentions.0.proj_in.bias: sum: 27.6503  dtype: Float32 shape: [1280]
159: down_blocks.2.attentions.0.proj_in.weight: sum: 900.5878  dtype: Float32 shape: [1280,1280]
160: down_blocks.2.attentions.0.proj_out.bias: sum: 26.9397  dtype: Float32 shape: [1280]
161: down_blocks.2.attentions.0.proj_out.weight: sum: 2769.1646  dtype: Float32 shape: [1280,1280]
162: down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 529.7114  dtype: Float32 shape: [1280,1280]
163: down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 6.0883  dtype: Float32 shape: [1280]
164: down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 5255.6016  dtype: Float32 shape: [1280,1280]
165: down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 1325.3484  dtype: Float32 shape: [1280,1280]
166: down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: -30.2449  dtype: Float32 shape: [1280,1280]
167: down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 902.5693  dtype: Float32 shape: [1280,1024]
168: down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: -15.9488  dtype: Float32 shape: [1280]
169: down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 6.6647  dtype: Float32 shape: [1280,1280]
170: down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 856.8334  dtype: Float32 shape: [1280,1280]
171: down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 129.1303  dtype: Float32 shape: [1280,1024]
172: down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 87.425  dtype: Float32 shape: [10240]
173: down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 3143.8833  dtype: Float32 shape: [10240,1280]
174: down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: 46.475  dtype: Float32 shape: [1280]
175: down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 2698.2341  dtype: Float32 shape: [1280,5120]
176: down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias: sum: 25.8477  dtype: Float32 shape: [1280]
177: down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight: sum: 23.8109  dtype: Float32 shape: [1280]
178: down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias: sum: 30.8707  dtype: Float32 shape: [1280]
179: down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight: sum: 23.8088  dtype: Float32 shape: [1280]
180: down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias: sum: 29.6915  dtype: Float32 shape: [1280]
181: down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight: sum: 23.8378  dtype: Float32 shape: [1280]
182: down_blocks.2.attentions.1.norm.bias: sum: 23.9127  dtype: Float32 shape: [1280]
183: down_blocks.2.attentions.1.norm.weight: sum: 23.8593  dtype: Float32 shape: [1280]
184: down_blocks.2.attentions.1.proj_in.bias: sum: -16.1696  dtype: Float32 shape: [1280]
185: down_blocks.2.attentions.1.proj_in.weight: sum: 746.9254  dtype: Float32 shape: [1280,1280]
186: down_blocks.2.attentions.1.proj_out.bias: sum: 30.217  dtype: Float32 shape: [1280]
187: down_blocks.2.attentions.1.proj_out.weight: sum: 844.6777  dtype: Float32 shape: [1280,1280]
188: down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: 1241.6497  dtype: Float32 shape: [1280,1280]
189: down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 14.0707  dtype: Float32 shape: [1280]
190: down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 611.3482  dtype: Float32 shape: [1280,1280]
191: down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: 959.1938  dtype: Float32 shape: [1280,1280]
192: down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 872.4112  dtype: Float32 shape: [1280,1280]
193: down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 891.3211  dtype: Float32 shape: [1280,1024]
194: down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: 16.3594  dtype: Float32 shape: [1280]
195: down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: -178.3912  dtype: Float32 shape: [1280,1280]
196: down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: -13636.627  dtype: Float32 shape: [1280,1280]
197: down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: 880.0995  dtype: Float32 shape: [1280,1024]
198: down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 87.2694  dtype: Float32 shape: [10240]
199: down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 3878.3948  dtype: Float32 shape: [10240,1280]
200: down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: 19.6968  dtype: Float32 shape: [1280]
201: down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: 2006.4825  dtype: Float32 shape: [1280,5120]
202: down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias: sum: 24.0635  dtype: Float32 shape: [1280]
203: down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight: sum: 23.8272  dtype: Float32 shape: [1280]
204: down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias: sum: 7.0867  dtype: Float32 shape: [1280]
205: down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight: sum: 23.8567  dtype: Float32 shape: [1280]
206: down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias: sum: 22.707  dtype: Float32 shape: [1280]
207: down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight: sum: 23.8477  dtype: Float32 shape: [1280]
208: down_blocks.2.downsamplers.0.conv.bias: sum: 25.3579  dtype: Float32 shape: [1280]
209: down_blocks.2.downsamplers.0.conv.weight: sum: 2574.3228  dtype: Float32 shape: [1280,1280,3,3]
210: down_blocks.2.resnets.0.conv1.bias: sum: 23.8408  dtype: Float32 shape: [1280]
211: down_blocks.2.resnets.0.conv1.weight: sum: 1902.6584  dtype: Float32 shape: [1280,640,3,3]
212: down_blocks.2.resnets.0.conv2.bias: sum: 29.6167  dtype: Float32 shape: [1280]
213: down_blocks.2.resnets.0.conv2.weight: sum: 4639.84  dtype: Float32 shape: [1280,1280,3,3]
214: down_blocks.2.resnets.0.conv_shortcut.bias: sum: 29.8199  dtype: Float32 shape: [1280]
215: down_blocks.2.resnets.0.conv_shortcut.weight: sum: 589.2052  dtype: Float32 shape: [1280,640,1,1]
216: down_blocks.2.resnets.0.norm1.bias: sum: 16.3388  dtype: Float32 shape: [640]
217: down_blocks.2.resnets.0.norm1.weight: sum: 16.7495  dtype: Float32 shape: [640]
218: down_blocks.2.resnets.0.norm2.bias: sum: 23.607  dtype: Float32 shape: [1280]
219: down_blocks.2.resnets.0.norm2.weight: sum: 23.7451  dtype: Float32 shape: [1280]
220: down_blocks.2.resnets.0.time_emb_proj.bias: sum: 23.8891  dtype: Float32 shape: [1280]
221: down_blocks.2.resnets.0.time_emb_proj.weight: sum: 920.9379  dtype: Float32 shape: [1280,1280]
222: down_blocks.2.resnets.1.conv1.bias: sum: 23.3195  dtype: Float32 shape: [1280]
223: down_blocks.2.resnets.1.conv1.weight: sum: 2243.7852  dtype: Float32 shape: [1280,1280,3,3]
224: down_blocks.2.resnets.1.conv2.bias: sum: 30.5444  dtype: Float32 shape: [1280]
225: down_blocks.2.resnets.1.conv2.weight: sum: 2865.5505  dtype: Float32 shape: [1280,1280,3,3]
226: down_blocks.2.resnets.1.norm1.bias: sum: 23.4891  dtype: Float32 shape: [1280]
227: down_blocks.2.resnets.1.norm1.weight: sum: 23.8966  dtype: Float32 shape: [1280]
228: down_blocks.2.resnets.1.norm2.bias: sum: 23.771  dtype: Float32 shape: [1280]
229: down_blocks.2.resnets.1.norm2.weight: sum: 23.8015  dtype: Float32 shape: [1280]
230: down_blocks.2.resnets.1.time_emb_proj.bias: sum: 23.36  dtype: Float32 shape: [1280]
231: down_blocks.2.resnets.1.time_emb_proj.weight: sum: 844.0355  dtype: Float32 shape: [1280,1280]
232: down_blocks.3.resnets.0.conv1.bias: sum: 24.002  dtype: Float32 shape: [1280]
233: down_blocks.3.resnets.0.conv1.weight: sum: 2566.9465  dtype: Float32 shape: [1280,1280,3,3]
234: down_blocks.3.resnets.0.conv2.bias: sum: 24.2182  dtype: Float32 shape: [1280]
235: down_blocks.3.resnets.0.conv2.weight: sum: 841.0302  dtype: Float32 shape: [1280,1280,3,3]
236: down_blocks.3.resnets.0.norm1.bias: sum: 23.5541  dtype: Float32 shape: [1280]
237: down_blocks.3.resnets.0.norm1.weight: sum: 23.8159  dtype: Float32 shape: [1280]
238: down_blocks.3.resnets.0.norm2.bias: sum: 23.8719  dtype: Float32 shape: [1280]
239: down_blocks.3.resnets.0.norm2.weight: sum: 23.8725  dtype: Float32 shape: [1280]
240: down_blocks.3.resnets.0.time_emb_proj.bias: sum: 23.9832  dtype: Float32 shape: [1280]
241: down_blocks.3.resnets.0.time_emb_proj.weight: sum: 865.2953  dtype: Float32 shape: [1280,1280]
242: down_blocks.3.resnets.1.conv1.bias: sum: 23.7957  dtype: Float32 shape: [1280]
243: down_blocks.3.resnets.1.conv1.weight: sum: 2516.139  dtype: Float32 shape: [1280,1280,3,3]
244: down_blocks.3.resnets.1.conv2.bias: sum: 25.2701  dtype: Float32 shape: [1280]
245: down_blocks.3.resnets.1.conv2.weight: sum: 2594.0896  dtype: Float32 shape: [1280,1280,3,3]
246: down_blocks.3.resnets.1.norm1.bias: sum: 23.9597  dtype: Float32 shape: [1280]
247: down_blocks.3.resnets.1.norm1.weight: sum: 23.925  dtype: Float32 shape: [1280]
248: down_blocks.3.resnets.1.norm2.bias: sum: 23.841  dtype: Float32 shape: [1280]
249: down_blocks.3.resnets.1.norm2.weight: sum: 23.7858  dtype: Float32 shape: [1280]
250: down_blocks.3.resnets.1.time_emb_proj.bias: sum: 23.8002  dtype: Float32 shape: [1280]
251: down_blocks.3.resnets.1.time_emb_proj.weight: sum: 850.6371  dtype: Float32 shape: [1280,1280]
252: mid_block.attentions.0.norm.bias: sum: 23.386  dtype: Float32 shape: [1280]
253: mid_block.attentions.0.norm.weight: sum: 23.893  dtype: Float32 shape: [1280]
254: mid_block.attentions.0.proj_in.bias: sum: 86.9416  dtype: Float32 shape: [1280]
255: mid_block.attentions.0.proj_in.weight: sum: 1059.4745  dtype: Float32 shape: [1280,1280]
256: mid_block.attentions.0.proj_out.bias: sum: 24.6452  dtype: Float32 shape: [1280]
257: mid_block.attentions.0.proj_out.weight: sum: 967.3807  dtype: Float32 shape: [1280,1280]
258: mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 830.0242  dtype: Float32 shape: [1280,1280]
259: mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 3.7589  dtype: Float32 shape: [1280]
260: mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 1376.1903  dtype: Float32 shape: [1280,1280]
261: mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 416.1542  dtype: Float32 shape: [1280,1280]
262: mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 1406.276  dtype: Float32 shape: [1280,1280]
263: mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 675.8207  dtype: Float32 shape: [1280,1024]
264: mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: 17.4003  dtype: Float32 shape: [1280]
265: mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 657.8045  dtype: Float32 shape: [1280,1280]
266: mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 844.1844  dtype: Float32 shape: [1280,1280]
267: mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 683.3088  dtype: Float32 shape: [1280,1024]
268: mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 83.8573  dtype: Float32 shape: [10240]
269: mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 3003.9236  dtype: Float32 shape: [10240,1280]
270: mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: -1.0667  dtype: Float32 shape: [1280]
271: mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 1538.6702  dtype: Float32 shape: [1280,5120]
272: mid_block.attentions.0.transformer_blocks.0.norm1.bias: sum: 10.7945  dtype: Float32 shape: [1280]
273: mid_block.attentions.0.transformer_blocks.0.norm1.weight: sum: 23.8107  dtype: Float32 shape: [1280]
274: mid_block.attentions.0.transformer_blocks.0.norm2.bias: sum: -5.4414  dtype: Float32 shape: [1280]
275: mid_block.attentions.0.transformer_blocks.0.norm2.weight: sum: 23.8621  dtype: Float32 shape: [1280]
276: mid_block.attentions.0.transformer_blocks.0.norm3.bias: sum: 22.7342  dtype: Float32 shape: [1280]
277: mid_block.attentions.0.transformer_blocks.0.norm3.weight: sum: 23.8243  dtype: Float32 shape: [1280]
278: mid_block.resnets.0.conv1.bias: sum: 24.2532  dtype: Float32 shape: [1280]
279: mid_block.resnets.0.conv1.weight: sum: 3259.447  dtype: Float32 shape: [1280,1280,3,3]
280: mid_block.resnets.0.conv2.bias: sum: 24.7454  dtype: Float32 shape: [1280]
281: mid_block.resnets.0.conv2.weight: sum: 2061.6743  dtype: Float32 shape: [1280,1280,3,3]
282: mid_block.resnets.0.norm1.bias: sum: 24.6029  dtype: Float32 shape: [1280]
283: mid_block.resnets.0.norm1.weight: sum: 24.0089  dtype: Float32 shape: [1280]
284: mid_block.resnets.0.norm2.bias: sum: 23.85  dtype: Float32 shape: [1280]
285: mid_block.resnets.0.norm2.weight: sum: 23.7325  dtype: Float32 shape: [1280]
286: mid_block.resnets.0.time_emb_proj.bias: sum: 24.269  dtype: Float32 shape: [1280]
287: mid_block.resnets.0.time_emb_proj.weight: sum: 868.6548  dtype: Float32 shape: [1280,1280]
288: mid_block.resnets.1.conv1.bias: sum: 23.9013  dtype: Float32 shape: [1280]
289: mid_block.resnets.1.conv1.weight: sum: 2235.548  dtype: Float32 shape: [1280,1280,3,3]
290: mid_block.resnets.1.conv2.bias: sum: 21.0541  dtype: Float32 shape: [1280]
291: mid_block.resnets.1.conv2.weight: sum: 1805.0852  dtype: Float32 shape: [1280,1280,3,3]
292: mid_block.resnets.1.norm1.bias: sum: 24.9865  dtype: Float32 shape: [1280]
293: mid_block.resnets.1.norm1.weight: sum: 23.99  dtype: Float32 shape: [1280]
294: mid_block.resnets.1.norm2.bias: sum: 24.2113  dtype: Float32 shape: [1280]
295: mid_block.resnets.1.norm2.weight: sum: 23.3811  dtype: Float32 shape: [1280]
296: mid_block.resnets.1.time_emb_proj.bias: sum: 23.8373  dtype: Float32 shape: [1280]
297: mid_block.resnets.1.time_emb_proj.weight: sum: 861.3364  dtype: Float32 shape: [1280,1280]
298: time_embedding.linear_1.bias: sum: 21.1321  dtype: Float32 shape: [1280]
299: time_embedding.linear_1.weight: sum: 398.2963  dtype: Float32 shape: [1280,320]
300: time_embedding.linear_2.bias: sum: 13.8397  dtype: Float32 shape: [1280]
301: time_embedding.linear_2.weight: sum: 851.0931  dtype: Float32 shape: [1280,1280]
302: up_blocks.0.resnets.0.conv1.bias: sum: 23.6089  dtype: Float32 shape: [1280]
303: up_blocks.0.resnets.0.conv1.weight: sum: 3543.6223  dtype: Float32 shape: [1280,2560,3,3]
304: up_blocks.0.resnets.0.conv2.bias: sum: 42.1856  dtype: Float32 shape: [1280]
305: up_blocks.0.resnets.0.conv2.weight: sum: 2853.3188  dtype: Float32 shape: [1280,1280,3,3]
306: up_blocks.0.resnets.0.conv_shortcut.bias: sum: 41.9782  dtype: Float32 shape: [1280]
307: up_blocks.0.resnets.0.conv_shortcut.weight: sum: 1193.3606  dtype: Float32 shape: [1280,2560,1,1]
308: up_blocks.0.resnets.0.norm1.bias: sum: 29.5854  dtype: Float32 shape: [2560]
309: up_blocks.0.resnets.0.norm1.weight: sum: 29.8002  dtype: Float32 shape: [2560]
310: up_blocks.0.resnets.0.norm2.bias: sum: 24.5052  dtype: Float32 shape: [1280]
311: up_blocks.0.resnets.0.norm2.weight: sum: 23.9404  dtype: Float32 shape: [1280]
312: up_blocks.0.resnets.0.time_emb_proj.bias: sum: 23.6203  dtype: Float32 shape: [1280]
313: up_blocks.0.resnets.0.time_emb_proj.weight: sum: 840.4621  dtype: Float32 shape: [1280,1280]
314: up_blocks.0.resnets.1.conv1.bias: sum: 23.5986  dtype: Float32 shape: [1280]
315: up_blocks.0.resnets.1.conv1.weight: sum: 3548.4937  dtype: Float32 shape: [1280,2560,3,3]
316: up_blocks.0.resnets.1.conv2.bias: sum: 38.4252  dtype: Float32 shape: [1280]
317: up_blocks.0.resnets.1.conv2.weight: sum: 2383.2327  dtype: Float32 shape: [1280,1280,3,3]
318: up_blocks.0.resnets.1.conv_shortcut.bias: sum: 39.8808  dtype: Float32 shape: [1280]
319: up_blocks.0.resnets.1.conv_shortcut.weight: sum: 977.8298  dtype: Float32 shape: [1280,2560,1,1]
320: up_blocks.0.resnets.1.norm1.bias: sum: 31.1994  dtype: Float32 shape: [2560]
321: up_blocks.0.resnets.1.norm1.weight: sum: 34.9473  dtype: Float32 shape: [2560]
322: up_blocks.0.resnets.1.norm2.bias: sum: 23.8226  dtype: Float32 shape: [1280]
323: up_blocks.0.resnets.1.norm2.weight: sum: 24.0228  dtype: Float32 shape: [1280]
324: up_blocks.0.resnets.1.time_emb_proj.bias: sum: 23.5269  dtype: Float32 shape: [1280]
325: up_blocks.0.resnets.1.time_emb_proj.weight: sum: 850.2302  dtype: Float32 shape: [1280,1280]
326: up_blocks.0.resnets.2.conv1.bias: sum: 22.9189  dtype: Float32 shape: [1280]
327: up_blocks.0.resnets.2.conv1.weight: sum: 4237.1123  dtype: Float32 shape: [1280,2560,3,3]
328: up_blocks.0.resnets.2.conv2.bias: sum: 40.9469  dtype: Float32 shape: [1280]
329: up_blocks.0.resnets.2.conv2.weight: sum: 3670.2869  dtype: Float32 shape: [1280,1280,3,3]
330: up_blocks.0.resnets.2.conv_shortcut.bias: sum: 41.4126  dtype: Float32 shape: [1280]
331: up_blocks.0.resnets.2.conv_shortcut.weight: sum: 166.2313  dtype: Float32 shape: [1280,2560,1,1]
332: up_blocks.0.resnets.2.norm1.bias: sum: 31.6164  dtype: Float32 shape: [2560]
333: up_blocks.0.resnets.2.norm1.weight: sum: 33.686  dtype: Float32 shape: [2560]
334: up_blocks.0.resnets.2.norm2.bias: sum: 23.502  dtype: Float32 shape: [1280]
335: up_blocks.0.resnets.2.norm2.weight: sum: 23.8026  dtype: Float32 shape: [1280]
336: up_blocks.0.resnets.2.time_emb_proj.bias: sum: 22.9683  dtype: Float32 shape: [1280]
337: up_blocks.0.resnets.2.time_emb_proj.weight: sum: 834.605  dtype: Float32 shape: [1280,1280]
338: up_blocks.0.upsamplers.0.conv.bias: sum: 25.8813  dtype: Float32 shape: [1280]
339: up_blocks.0.upsamplers.0.conv.weight: sum: 2005.6428  dtype: Float32 shape: [1280,1280,3,3]
340: up_blocks.1.attentions.0.norm.bias: sum: 28.1245  dtype: Float32 shape: [1280]
341: up_blocks.1.attentions.0.norm.weight: sum: 23.913  dtype: Float32 shape: [1280]
342: up_blocks.1.attentions.0.proj_in.bias: sum: 20.6894  dtype: Float32 shape: [1280]
343: up_blocks.1.attentions.0.proj_in.weight: sum: 893.3663  dtype: Float32 shape: [1280,1280]
344: up_blocks.1.attentions.0.proj_out.bias: sum: 22.3266  dtype: Float32 shape: [1280]
345: up_blocks.1.attentions.0.proj_out.weight: sum: 593.8935  dtype: Float32 shape: [1280,1280]
346: up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 1559.6619  dtype: Float32 shape: [1280,1280]
347: up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: -1046.4143  dtype: Float32 shape: [1280]
348: up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 1041.0447  dtype: Float32 shape: [1280,1280]
349: up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 879.2036  dtype: Float32 shape: [1280,1280]
350: up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 1505.1838  dtype: Float32 shape: [1280,1280]
351: up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 342.0148  dtype: Float32 shape: [1280,1024]
352: up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: 397.9466  dtype: Float32 shape: [1280]
353: up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 890.9045  dtype: Float32 shape: [1280,1280]
354: up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 940.42  dtype: Float32 shape: [1280,1280]
355: up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: -576.3393  dtype: Float32 shape: [1280,1024]
356: up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 86.8325  dtype: Float32 shape: [10240]
357: up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 3249.5544  dtype: Float32 shape: [10240,1280]
358: up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: -84.6718  dtype: Float32 shape: [1280]
359: up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 13442.258  dtype: Float32 shape: [1280,5120]
360: up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias: sum: 18.3505  dtype: Float32 shape: [1280]
361: up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight: sum: 23.8811  dtype: Float32 shape: [1280]
362: up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias: sum: -3.9164  dtype: Float32 shape: [1280]
363: up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight: sum: 23.8609  dtype: Float32 shape: [1280]
364: up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias: sum: 6.0581  dtype: Float32 shape: [1280]
365: up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight: sum: 23.861  dtype: Float32 shape: [1280]
366: up_blocks.1.attentions.1.norm.bias: sum: 17.1847  dtype: Float32 shape: [1280]
367: up_blocks.1.attentions.1.norm.weight: sum: 23.7881  dtype: Float32 shape: [1280]
368: up_blocks.1.attentions.1.proj_in.bias: sum: 47.1739  dtype: Float32 shape: [1280]
369: up_blocks.1.attentions.1.proj_in.weight: sum: 898.881  dtype: Float32 shape: [1280,1280]
370: up_blocks.1.attentions.1.proj_out.bias: sum: 24.3856  dtype: Float32 shape: [1280]
371: up_blocks.1.attentions.1.proj_out.weight: sum: 808.877  dtype: Float32 shape: [1280,1280]
372: up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: -1360.3962  dtype: Float32 shape: [1280,1280]
373: up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 12.0083  dtype: Float32 shape: [1280]
374: up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 1219.2856  dtype: Float32 shape: [1280,1280]
375: up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: -181.5216  dtype: Float32 shape: [1280,1280]
376: up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 814.302  dtype: Float32 shape: [1280,1280]
377: up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 573.4301  dtype: Float32 shape: [1280,1024]
378: up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: 15.1162  dtype: Float32 shape: [1280]
379: up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: 1686.732  dtype: Float32 shape: [1280,1280]
380: up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: -2655.583  dtype: Float32 shape: [1280,1280]
381: up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: 1181.9813  dtype: Float32 shape: [1280,1024]
382: up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 87.501  dtype: Float32 shape: [10240]
383: up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 4547.381  dtype: Float32 shape: [10240,1280]
384: up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: 6.3729  dtype: Float32 shape: [1280]
385: up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: -2560.9897  dtype: Float32 shape: [1280,5120]
386: up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias: sum: 25.8991  dtype: Float32 shape: [1280]
387: up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight: sum: 23.8298  dtype: Float32 shape: [1280]
388: up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias: sum: 28.5758  dtype: Float32 shape: [1280]
389: up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight: sum: 23.8224  dtype: Float32 shape: [1280]
390: up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias: sum: 30.2142  dtype: Float32 shape: [1280]
391: up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight: sum: 23.8374  dtype: Float32 shape: [1280]
392: up_blocks.1.attentions.2.norm.bias: sum: 16.2714  dtype: Float32 shape: [1280]
393: up_blocks.1.attentions.2.norm.weight: sum: 23.7735  dtype: Float32 shape: [1280]
394: up_blocks.1.attentions.2.proj_in.bias: sum: -134.6378  dtype: Float32 shape: [1280]
395: up_blocks.1.attentions.2.proj_in.weight: sum: 744.3852  dtype: Float32 shape: [1280,1280]
396: up_blocks.1.attentions.2.proj_out.bias: sum: 27.2858  dtype: Float32 shape: [1280]
397: up_blocks.1.attentions.2.proj_out.weight: sum: 837.2172  dtype: Float32 shape: [1280,1280]
398: up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight: sum: 814.1244  dtype: Float32 shape: [1280,1280]
399: up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias: sum: 53.7232  dtype: Float32 shape: [1280]
400: up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight: sum: 1302.5045  dtype: Float32 shape: [1280,1280]
401: up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight: sum: 724.552  dtype: Float32 shape: [1280,1280]
402: up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight: sum: -3025.6787  dtype: Float32 shape: [1280,1280]
403: up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight: sum: 460.4524  dtype: Float32 shape: [1280,1024]
404: up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias: sum: 50.9172  dtype: Float32 shape: [1280]
405: up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight: sum: 924.9661  dtype: Float32 shape: [1280,1280]
406: up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight: sum: 248.6207  dtype: Float32 shape: [1280,1280]
407: up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight: sum: -942.9703  dtype: Float32 shape: [1280,1024]
408: up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias: sum: 87.3658  dtype: Float32 shape: [10240]
409: up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight: sum: 3126.3706  dtype: Float32 shape: [10240,1280]
410: up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias: sum: -57.3711  dtype: Float32 shape: [1280]
411: up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight: sum: 1806.4338  dtype: Float32 shape: [1280,5120]
412: up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias: sum: 24.1567  dtype: Float32 shape: [1280]
413: up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight: sum: 23.822  dtype: Float32 shape: [1280]
414: up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias: sum: 23.9142  dtype: Float32 shape: [1280]
415: up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight: sum: 23.8472  dtype: Float32 shape: [1280]
416: up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias: sum: 22.3553  dtype: Float32 shape: [1280]
417: up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight: sum: 23.8274  dtype: Float32 shape: [1280]
418: up_blocks.1.resnets.0.conv1.bias: sum: 25.1502  dtype: Float32 shape: [1280]
419: up_blocks.1.resnets.0.conv1.weight: sum: 2980.653  dtype: Float32 shape: [1280,2560,3,3]
420: up_blocks.1.resnets.0.conv2.bias: sum: 30.101  dtype: Float32 shape: [1280]
421: up_blocks.1.resnets.0.conv2.weight: sum: 2772.6484  dtype: Float32 shape: [1280,1280,3,3]
422: up_blocks.1.resnets.0.conv_shortcut.bias: sum: 31.3711  dtype: Float32 shape: [1280]
423: up_blocks.1.resnets.0.conv_shortcut.weight: sum: 2239.0063  dtype: Float32 shape: [1280,2560,1,1]
424: up_blocks.1.resnets.0.norm1.bias: sum: 35.4623  dtype: Float32 shape: [2560]
425: up_blocks.1.resnets.0.norm1.weight: sum: 42.0323  dtype: Float32 shape: [2560]
426: up_blocks.1.resnets.0.norm2.bias: sum: 23.9854  dtype: Float32 shape: [1280]
427: up_blocks.1.resnets.0.norm2.weight: sum: 23.8598  dtype: Float32 shape: [1280]
428: up_blocks.1.resnets.0.time_emb_proj.bias: sum: 25.1095  dtype: Float32 shape: [1280]
429: up_blocks.1.resnets.0.time_emb_proj.weight: sum: 865.5268  dtype: Float32 shape: [1280,1280]
430: up_blocks.1.resnets.1.conv1.bias: sum: 23.8508  dtype: Float32 shape: [1280]
431: up_blocks.1.resnets.1.conv1.weight: sum: 2729.1985  dtype: Float32 shape: [1280,2560,3,3]
432: up_blocks.1.resnets.1.conv2.bias: sum: -46.5817  dtype: Float32 shape: [1280]
433: up_blocks.1.resnets.1.conv2.weight: sum: 7091.996  dtype: Float32 shape: [1280,1280,3,3]
434: up_blocks.1.resnets.1.conv_shortcut.bias: sum: -39.3621  dtype: Float32 shape: [1280]
435: up_blocks.1.resnets.1.conv_shortcut.weight: sum: 1146.7461  dtype: Float32 shape: [1280,2560,1,1]
436: up_blocks.1.resnets.1.norm1.bias: sum: 25.8064  dtype: Float32 shape: [2560]
437: up_blocks.1.resnets.1.norm1.weight: sum: 29.4528  dtype: Float32 shape: [2560]
438: up_blocks.1.resnets.1.norm2.bias: sum: 24.3714  dtype: Float32 shape: [1280]
439: up_blocks.1.resnets.1.norm2.weight: sum: 23.9624  dtype: Float32 shape: [1280]
440: up_blocks.1.resnets.1.time_emb_proj.bias: sum: 23.748  dtype: Float32 shape: [1280]
441: up_blocks.1.resnets.1.time_emb_proj.weight: sum: 857.6411  dtype: Float32 shape: [1280,1280]
442: up_blocks.1.resnets.2.conv1.bias: sum: 22.7969  dtype: Float32 shape: [1280]
443: up_blocks.1.resnets.2.conv1.weight: sum: 3405.712  dtype: Float32 shape: [1280,1920,3,3]
444: up_blocks.1.resnets.2.conv2.bias: sum: 29.939  dtype: Float32 shape: [1280]
445: up_blocks.1.resnets.2.conv2.weight: sum: 3467.1208  dtype: Float32 shape: [1280,1280,3,3]
446: up_blocks.1.resnets.2.conv_shortcut.bias: sum: 29.6158  dtype: Float32 shape: [1280]
447: up_blocks.1.resnets.2.conv_shortcut.weight: sum: 912.774  dtype: Float32 shape: [1280,1920,1,1]
448: up_blocks.1.resnets.2.norm1.bias: sum: 24.64  dtype: Float32 shape: [1920]
449: up_blocks.1.resnets.2.norm1.weight: sum: 26.2799  dtype: Float32 shape: [1920]
450: up_blocks.1.resnets.2.norm2.bias: sum: 23.4014  dtype: Float32 shape: [1280]
451: up_blocks.1.resnets.2.norm2.weight: sum: 24.6135  dtype: Float32 shape: [1280]
452: up_blocks.1.resnets.2.time_emb_proj.bias: sum: 22.6219  dtype: Float32 shape: [1280]
453: up_blocks.1.resnets.2.time_emb_proj.weight: sum: 890.712  dtype: Float32 shape: [1280,1280]
454: up_blocks.1.upsamplers.0.conv.bias: sum: 12.6038  dtype: Float32 shape: [1280]
455: up_blocks.1.upsamplers.0.conv.weight: sum: 2682.0288  dtype: Float32 shape: [1280,1280,3,3]
456: up_blocks.2.attentions.0.norm.bias: sum: 17.0069  dtype: Float32 shape: [640]
457: up_blocks.2.attentions.0.norm.weight: sum: 16.7988  dtype: Float32 shape: [640]
458: up_blocks.2.attentions.0.proj_in.bias: sum: 21.1582  dtype: Float32 shape: [640]
459: up_blocks.2.attentions.0.proj_in.weight: sum: 4867.3374  dtype: Float32 shape: [640,640]
460: up_blocks.2.attentions.0.proj_out.bias: sum: 17.8759  dtype: Float32 shape: [640]
461: up_blocks.2.attentions.0.proj_out.weight: sum: 827.42  dtype: Float32 shape: [640,640]
462: up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 543.1696  dtype: Float32 shape: [640,640]
463: up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 13.1096  dtype: Float32 shape: [640]
464: up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 511.5144  dtype: Float32 shape: [640,640]
465: up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 300.3072  dtype: Float32 shape: [640,640]
466: up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 954.5306  dtype: Float32 shape: [640,640]
467: up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 714.8966  dtype: Float32 shape: [640,1024]
468: up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: 19.1156  dtype: Float32 shape: [640]
469: up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: -188.3972  dtype: Float32 shape: [640,640]
470: up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 681.7699  dtype: Float32 shape: [640,640]
471: up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 583.9997  dtype: Float32 shape: [640,1024]
472: up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 57.8462  dtype: Float32 shape: [5120]
473: up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 1530.5823  dtype: Float32 shape: [5120,640]
474: up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: 21.0334  dtype: Float32 shape: [640]
475: up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: -464.5076  dtype: Float32 shape: [640,2560]
476: up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias: sum: 16.6547  dtype: Float32 shape: [640]
477: up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight: sum: 16.8837  dtype: Float32 shape: [640]
478: up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias: sum: 8.3398  dtype: Float32 shape: [640]
479: up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight: sum: 16.8821  dtype: Float32 shape: [640]
480: up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias: sum: 15.596  dtype: Float32 shape: [640]
481: up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight: sum: 16.8518  dtype: Float32 shape: [640]
482: up_blocks.2.attentions.1.norm.bias: sum: 18.025  dtype: Float32 shape: [640]
483: up_blocks.2.attentions.1.norm.weight: sum: 16.8962  dtype: Float32 shape: [640]
484: up_blocks.2.attentions.1.proj_in.bias: sum: 14.6687  dtype: Float32 shape: [640]
485: up_blocks.2.attentions.1.proj_in.weight: sum: 575.1169  dtype: Float32 shape: [640,640]
486: up_blocks.2.attentions.1.proj_out.bias: sum: 17.5652  dtype: Float32 shape: [640]
487: up_blocks.2.attentions.1.proj_out.weight: sum: 1349.6527  dtype: Float32 shape: [640,640]
488: up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: 872.0612  dtype: Float32 shape: [640,640]
489: up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 26.6222  dtype: Float32 shape: [640]
490: up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 603.351  dtype: Float32 shape: [640,640]
491: up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: 516.6677  dtype: Float32 shape: [640,640]
492: up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 354.5802  dtype: Float32 shape: [640,640]
493: up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 901.6642  dtype: Float32 shape: [640,1024]
494: up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: 27.2617  dtype: Float32 shape: [640]
495: up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: 656.5854  dtype: Float32 shape: [640,640]
496: up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: 826.6026  dtype: Float32 shape: [640,640]
497: up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: -255.7223  dtype: Float32 shape: [640,1024]
498: up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 72.6158  dtype: Float32 shape: [5120]
499: up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 1673.4926  dtype: Float32 shape: [5120,640]
500: up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: 8.3699  dtype: Float32 shape: [640]
501: up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: 1014.0261  dtype: Float32 shape: [640,2560]
502: up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias: sum: 15.8737  dtype: Float32 shape: [640]
503: up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight: sum: 16.8006  dtype: Float32 shape: [640]
504: up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias: sum: 28.9957  dtype: Float32 shape: [640]
505: up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight: sum: 16.8414  dtype: Float32 shape: [640]
506: up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias: sum: 15.6113  dtype: Float32 shape: [640]
507: up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight: sum: 16.8407  dtype: Float32 shape: [640]
508: up_blocks.2.attentions.2.norm.bias: sum: 22.019  dtype: Float32 shape: [640]
509: up_blocks.2.attentions.2.norm.weight: sum: 16.8247  dtype: Float32 shape: [640]
510: up_blocks.2.attentions.2.proj_in.bias: sum: -68.758  dtype: Float32 shape: [640]
511: up_blocks.2.attentions.2.proj_in.weight: sum: 314.3989  dtype: Float32 shape: [640,640]
512: up_blocks.2.attentions.2.proj_out.bias: sum: 23.2543  dtype: Float32 shape: [640]
513: up_blocks.2.attentions.2.proj_out.weight: sum: 607.9626  dtype: Float32 shape: [640,640]
514: up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight: sum: 647.4699  dtype: Float32 shape: [640,640]
515: up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias: sum: 39.2299  dtype: Float32 shape: [640]
516: up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight: sum: 8602.521  dtype: Float32 shape: [640,640]
517: up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight: sum: 1228.7751  dtype: Float32 shape: [640,640]
518: up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight: sum: 69.2278  dtype: Float32 shape: [640,640]
519: up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight: sum: 495.8378  dtype: Float32 shape: [640,1024]
520: up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias: sum: 50.3216  dtype: Float32 shape: [640]
521: up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight: sum: 540.4602  dtype: Float32 shape: [640,640]
522: up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight: sum: 406.6285  dtype: Float32 shape: [640,640]
523: up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight: sum: 659.5968  dtype: Float32 shape: [640,1024]
524: up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias: sum: 58.3779  dtype: Float32 shape: [5120]
525: up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight: sum: 1559.7041  dtype: Float32 shape: [5120,640]
526: up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias: sum: -358.7644  dtype: Float32 shape: [640]
527: up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight: sum: 547.1042  dtype: Float32 shape: [640,2560]
528: up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias: sum: 15.6433  dtype: Float32 shape: [640]
529: up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight: sum: 16.8454  dtype: Float32 shape: [640]
530: up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias: sum: 19.1548  dtype: Float32 shape: [640]
531: up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight: sum: 16.8352  dtype: Float32 shape: [640]
532: up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias: sum: 16.4695  dtype: Float32 shape: [640]
533: up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight: sum: 16.8368  dtype: Float32 shape: [640]
534: up_blocks.2.resnets.0.conv1.bias: sum: 16.9815  dtype: Float32 shape: [640]
535: up_blocks.2.resnets.0.conv1.weight: sum: 2052.73  dtype: Float32 shape: [640,1920,3,3]
536: up_blocks.2.resnets.0.conv2.bias: sum: 18.6774  dtype: Float32 shape: [640]
537: up_blocks.2.resnets.0.conv2.weight: sum: 1068.8114  dtype: Float32 shape: [640,640,3,3]
538: up_blocks.2.resnets.0.conv_shortcut.bias: sum: 18.8648  dtype: Float32 shape: [640]
539: up_blocks.2.resnets.0.conv_shortcut.weight: sum: 1089.0698  dtype: Float32 shape: [640,1920,1,1]
540: up_blocks.2.resnets.0.norm1.bias: sum: 23.6971  dtype: Float32 shape: [1920]
541: up_blocks.2.resnets.0.norm1.weight: sum: 26.8539  dtype: Float32 shape: [1920]
542: up_blocks.2.resnets.0.norm2.bias: sum: 17.276  dtype: Float32 shape: [640]
543: up_blocks.2.resnets.0.norm2.weight: sum: 16.9798  dtype: Float32 shape: [640]
544: up_blocks.2.resnets.0.time_emb_proj.bias: sum: 16.7273  dtype: Float32 shape: [640]
545: up_blocks.2.resnets.0.time_emb_proj.weight: sum: -1192.7318  dtype: Float32 shape: [640,1280]
546: up_blocks.2.resnets.1.conv1.bias: sum: 15.9386  dtype: Float32 shape: [640]
547: up_blocks.2.resnets.1.conv1.weight: sum: 1703.2546  dtype: Float32 shape: [640,1280,3,3]
548: up_blocks.2.resnets.1.conv2.bias: sum: 19.8736  dtype: Float32 shape: [640]
549: up_blocks.2.resnets.1.conv2.weight: sum: -1112.4348  dtype: Float32 shape: [640,640,3,3]
550: up_blocks.2.resnets.1.conv_shortcut.bias: sum: 19.7346  dtype: Float32 shape: [640]
551: up_blocks.2.resnets.1.conv_shortcut.weight: sum: 697.4757  dtype: Float32 shape: [640,1280,1,1]
552: up_blocks.2.resnets.1.norm1.bias: sum: 19.2316  dtype: Float32 shape: [1280]
553: up_blocks.2.resnets.1.norm1.weight: sum: 20.8704  dtype: Float32 shape: [1280]
554: up_blocks.2.resnets.1.norm2.bias: sum: 16.5988  dtype: Float32 shape: [640]
555: up_blocks.2.resnets.1.norm2.weight: sum: 16.797  dtype: Float32 shape: [640]
556: up_blocks.2.resnets.1.time_emb_proj.bias: sum: 16.0149  dtype: Float32 shape: [640]
557: up_blocks.2.resnets.1.time_emb_proj.weight: sum: 272.8932  dtype: Float32 shape: [640,1280]
558: up_blocks.2.resnets.2.conv1.bias: sum: 16.389  dtype: Float32 shape: [640]
559: up_blocks.2.resnets.2.conv1.weight: sum: 1428.4049  dtype: Float32 shape: [640,960,3,3]
560: up_blocks.2.resnets.2.conv2.bias: sum: 7.0888  dtype: Float32 shape: [640]
561: up_blocks.2.resnets.2.conv2.weight: sum: -174.518  dtype: Float32 shape: [640,640,3,3]
562: up_blocks.2.resnets.2.conv_shortcut.bias: sum: 6.5852  dtype: Float32 shape: [640]
563: up_blocks.2.resnets.2.conv_shortcut.weight: sum: 1286.8356  dtype: Float32 shape: [640,960,1,1]
564: up_blocks.2.resnets.2.norm1.bias: sum: 18.4642  dtype: Float32 shape: [960]
565: up_blocks.2.resnets.2.norm1.weight: sum: 19.3737  dtype: Float32 shape: [960]
566: up_blocks.2.resnets.2.norm2.bias: sum: 16.6324  dtype: Float32 shape: [640]
567: up_blocks.2.resnets.2.norm2.weight: sum: 16.7303  dtype: Float32 shape: [640]
568: up_blocks.2.resnets.2.time_emb_proj.bias: sum: 16.7468  dtype: Float32 shape: [640]
569: up_blocks.2.resnets.2.time_emb_proj.weight: sum: 476.8131  dtype: Float32 shape: [640,1280]
570: up_blocks.2.upsamplers.0.conv.bias: sum: 17.6116  dtype: Float32 shape: [640]
571: up_blocks.2.upsamplers.0.conv.weight: sum: 1804.3518  dtype: Float32 shape: [640,640,3,3]
572: up_blocks.3.attentions.0.norm.bias: sum: 13.4313  dtype: Float32 shape: [320]
573: up_blocks.3.attentions.0.norm.weight: sum: 11.8911  dtype: Float32 shape: [320]
574: up_blocks.3.attentions.0.proj_in.bias: sum: 5.4471  dtype: Float32 shape: [320]
575: up_blocks.3.attentions.0.proj_in.weight: sum: 501.7139  dtype: Float32 shape: [320,320]
576: up_blocks.3.attentions.0.proj_out.bias: sum: 11.8435  dtype: Float32 shape: [320]
577: up_blocks.3.attentions.0.proj_out.weight: sum: 208.1661  dtype: Float32 shape: [320,320]
578: up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight: sum: 132.4813  dtype: Float32 shape: [320,320]
579: up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias: sum: 15.2523  dtype: Float32 shape: [320]
580: up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight: sum: 211.365  dtype: Float32 shape: [320,320]
581: up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight: sum: 126.339  dtype: Float32 shape: [320,320]
582: up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight: sum: 311.9675  dtype: Float32 shape: [320,320]
583: up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight: sum: 612.3069  dtype: Float32 shape: [320,1024]
584: up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias: sum: 16.6468  dtype: Float32 shape: [320]
585: up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight: sum: 258.4374  dtype: Float32 shape: [320,320]
586: up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight: sum: 159.0946  dtype: Float32 shape: [320,320]
587: up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight: sum: 415.2324  dtype: Float32 shape: [320,1024]
588: up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias: sum: 43.559  dtype: Float32 shape: [2560]
589: up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight: sum: 811.0368  dtype: Float32 shape: [2560,320]
590: up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias: sum: 16.2991  dtype: Float32 shape: [320]
591: up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight: sum: 346.1626  dtype: Float32 shape: [320,1280]
592: up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias: sum: 10.9505  dtype: Float32 shape: [320]
593: up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight: sum: 11.8539  dtype: Float32 shape: [320]
594: up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias: sum: 11.6872  dtype: Float32 shape: [320]
595: up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight: sum: 11.9049  dtype: Float32 shape: [320]
596: up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias: sum: 11.2341  dtype: Float32 shape: [320]
597: up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight: sum: 11.9054  dtype: Float32 shape: [320]
598: up_blocks.3.attentions.1.norm.bias: sum: 15.2919  dtype: Float32 shape: [320]
599: up_blocks.3.attentions.1.norm.weight: sum: 12.0203  dtype: Float32 shape: [320]
600: up_blocks.3.attentions.1.proj_in.bias: sum: 128.0424  dtype: Float32 shape: [320]
601: up_blocks.3.attentions.1.proj_in.weight: sum: -374.8207  dtype: Float32 shape: [320,320]
602: up_blocks.3.attentions.1.proj_out.bias: sum: 11.3443  dtype: Float32 shape: [320]
603: up_blocks.3.attentions.1.proj_out.weight: sum: -148.5639  dtype: Float32 shape: [320,320]
604: up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight: sum: 243.0182  dtype: Float32 shape: [320,320]
605: up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias: sum: 31.191  dtype: Float32 shape: [320]
606: up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight: sum: 231.2073  dtype: Float32 shape: [320,320]
607: up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight: sum: 412.7525  dtype: Float32 shape: [320,320]
608: up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight: sum: 231.2159  dtype: Float32 shape: [320,320]
609: up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight: sum: 482.2709  dtype: Float32 shape: [320,1024]
610: up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias: sum: 16.9528  dtype: Float32 shape: [320]
611: up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight: sum: 489.9985  dtype: Float32 shape: [320,320]
612: up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight: sum: 232.1056  dtype: Float32 shape: [320,320]
613: up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight: sum: 165.3614  dtype: Float32 shape: [320,1024]
614: up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias: sum: 44.1959  dtype: Float32 shape: [2560]
615: up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight: sum: 808.6123  dtype: Float32 shape: [2560,320]
616: up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias: sum: 7.8005  dtype: Float32 shape: [320]
617: up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight: sum: 332.7416  dtype: Float32 shape: [320,1280]
618: up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias: sum: 12.1135  dtype: Float32 shape: [320]
619: up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight: sum: 11.8894  dtype: Float32 shape: [320]
620: up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias: sum: 11.7587  dtype: Float32 shape: [320]
621: up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight: sum: 11.8732  dtype: Float32 shape: [320]
622: up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias: sum: 11.9665  dtype: Float32 shape: [320]
623: up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight: sum: 11.8712  dtype: Float32 shape: [320]
624: up_blocks.3.attentions.2.norm.bias: sum: 11.5682  dtype: Float32 shape: [320]
625: up_blocks.3.attentions.2.norm.weight: sum: 11.9132  dtype: Float32 shape: [320]
626: up_blocks.3.attentions.2.proj_in.bias: sum: -17.6963  dtype: Float32 shape: [320]
627: up_blocks.3.attentions.2.proj_in.weight: sum: 117.2105  dtype: Float32 shape: [320,320]
628: up_blocks.3.attentions.2.proj_out.bias: sum: 11.83  dtype: Float32 shape: [320]
629: up_blocks.3.attentions.2.proj_out.weight: sum: 238.6199  dtype: Float32 shape: [320,320]
630: up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight: sum: 372.2649  dtype: Float32 shape: [320,320]
631: up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias: sum: 24.0613  dtype: Float32 shape: [320]
632: up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight: sum: 313.2307  dtype: Float32 shape: [320,320]
633: up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight: sum: 126.3652  dtype: Float32 shape: [320,320]
634: up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight: sum: 427.7222  dtype: Float32 shape: [320,320]
635: up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight: sum: 306.8216  dtype: Float32 shape: [320,1024]
636: up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias: sum: 21.2607  dtype: Float32 shape: [320]
637: up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight: sum: 258.685  dtype: Float32 shape: [320,320]
638: up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight: sum: 23.7167  dtype: Float32 shape: [320,320]
639: up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight: sum: -82.7945  dtype: Float32 shape: [320,1024]
640: up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias: sum: 43.329  dtype: Float32 shape: [2560]
641: up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight: sum: 798.5291  dtype: Float32 shape: [2560,320]
642: up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias: sum: 9.7653  dtype: Float32 shape: [320]
643: up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight: sum: 242.7398  dtype: Float32 shape: [320,1280]
644: up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias: sum: 12.203  dtype: Float32 shape: [320]
645: up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight: sum: 11.8854  dtype: Float32 shape: [320]
646: up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias: sum: 11.6771  dtype: Float32 shape: [320]
647: up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight: sum: 11.9236  dtype: Float32 shape: [320]
648: up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias: sum: 10.0902  dtype: Float32 shape: [320]
649: up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight: sum: 11.8916  dtype: Float32 shape: [320]
650: up_blocks.3.resnets.0.conv1.bias: sum: 12.6321  dtype: Float32 shape: [320]
651: up_blocks.3.resnets.0.conv1.weight: sum: 961.7749  dtype: Float32 shape: [320,960,3,3]
652: up_blocks.3.resnets.0.conv2.bias: sum: 12.7882  dtype: Float32 shape: [320]
653: up_blocks.3.resnets.0.conv2.weight: sum: -809.8294  dtype: Float32 shape: [320,320,3,3]
654: up_blocks.3.resnets.0.conv_shortcut.bias: sum: 12.8417  dtype: Float32 shape: [320]
655: up_blocks.3.resnets.0.conv_shortcut.weight: sum: 368.2988  dtype: Float32 shape: [320,960,1,1]
656: up_blocks.3.resnets.0.norm1.bias: sum: 16.3915  dtype: Float32 shape: [960]
657: up_blocks.3.resnets.0.norm1.weight: sum: 18.4653  dtype: Float32 shape: [960]
658: up_blocks.3.resnets.0.norm2.bias: sum: 11.7201  dtype: Float32 shape: [320]
659: up_blocks.3.resnets.0.norm2.weight: sum: 11.905  dtype: Float32 shape: [320]
660: up_blocks.3.resnets.0.time_emb_proj.bias: sum: 12.1193  dtype: Float32 shape: [320]
661: up_blocks.3.resnets.0.time_emb_proj.weight: sum: 392.5304  dtype: Float32 shape: [320,1280]
662: up_blocks.3.resnets.1.conv1.bias: sum: 11.5961  dtype: Float32 shape: [320]
663: up_blocks.3.resnets.1.conv1.weight: sum: 886.4987  dtype: Float32 shape: [320,640,3,3]
664: up_blocks.3.resnets.1.conv2.bias: sum: 12.1575  dtype: Float32 shape: [320]
665: up_blocks.3.resnets.1.conv2.weight: sum: 568.7806  dtype: Float32 shape: [320,320,3,3]
666: up_blocks.3.resnets.1.conv_shortcut.bias: sum: 12.0253  dtype: Float32 shape: [320]
667: up_blocks.3.resnets.1.conv_shortcut.weight: sum: 282.7709  dtype: Float32 shape: [320,640,1,1]
668: up_blocks.3.resnets.1.norm1.bias: sum: 15.4483  dtype: Float32 shape: [640]
669: up_blocks.3.resnets.1.norm1.weight: sum: 15.9002  dtype: Float32 shape: [640]
670: up_blocks.3.resnets.1.norm2.bias: sum: 12.0815  dtype: Float32 shape: [320]
671: up_blocks.3.resnets.1.norm2.weight: sum: 11.9023  dtype: Float32 shape: [320]
672: up_blocks.3.resnets.1.time_emb_proj.bias: sum: 11.7287  dtype: Float32 shape: [320]
673: up_blocks.3.resnets.1.time_emb_proj.weight: sum: 542.7047  dtype: Float32 shape: [320,1280]
674: up_blocks.3.resnets.2.conv1.bias: sum: 10.6437  dtype: Float32 shape: [320]
675: up_blocks.3.resnets.2.conv1.weight: sum: 946.9413  dtype: Float32 shape: [320,640,3,3]
676: up_blocks.3.resnets.2.conv2.bias: sum: 13.2402  dtype: Float32 shape: [320]
677: up_blocks.3.resnets.2.conv2.weight: sum: 692.0878  dtype: Float32 shape: [320,320,3,3]
678: up_blocks.3.resnets.2.conv_shortcut.bias: sum: 12.9665  dtype: Float32 shape: [320]
679: up_blocks.3.resnets.2.conv_shortcut.weight: sum: 300.155  dtype: Float32 shape: [320,640,1,1]
680: up_blocks.3.resnets.2.norm1.bias: sum: 14.7015  dtype: Float32 shape: [640]
681: up_blocks.3.resnets.2.norm1.weight: sum: 14.5974  dtype: Float32 shape: [640]
682: up_blocks.3.resnets.2.norm2.bias: sum: 11.5162  dtype: Float32 shape: [320]
683: up_blocks.3.resnets.2.norm2.weight: sum: 11.845  dtype: Float32 shape: [320]
684: up_blocks.3.resnets.2.time_emb_proj.bias: sum: 10.7973  dtype: Float32 shape: [320]
685: up_blocks.3.resnets.2.time_emb_proj.weight: sum: 461.614  dtype: Float32 shape: [320,1280]
